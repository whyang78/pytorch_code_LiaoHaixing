## 主要内容  
1. SGD实现，详见`SGD.py`  
    + 根据原理实现SGD优化算法，并调节batch_size和learning_rate观察其收敛效果。  
    + 得到结果图 `SGD.png`  
2. Momentum实现，详见 `Momentum.py`  
    + 根据原理实现Momentum优化算法。  
    + 得到结果图 `Momentum.png`  
3. Adagrad实现，详见 `Adagrad.py`  
    + 根据原理实现Adagrad优化算法。  
    + 得到结果图 `Adagrad.png`  
4. Rmsprop实现，详见 `Rmsprop.py`  
    + 根据原理实现Rmsprop优化算法。  
    + 得到结果图 `Rmsprop.png`  
5. Adadelta实现，详见 `Adadelta.py`  
    + 根据原理实现Adadelta优化算法。  
    + 得到结果图 `Adadelta.png`  
6. Adam实现，详见 `Adam.py`  
   + 根据原理实现Adam优化算法。  
   + 得到结果图 `Adam.png`
